import os
import cv2
import numpy as np
from PIL import Image
import streamlit as st
from datetime import datetime
import shutil
import requests
from ultralytics import YOLO
import onnxruntime as ort

# === ä¿®æ­£ Ultralytics è¨­å®šç›®éŒ„ï¼Œé¿å…é›²ç«¯è­¦å‘Š ===
os.environ["YOLO_CONFIG_DIR"] = "/tmp/Ultralytics"

# === åˆå§‹åŒ–èªè¨€ç‹€æ…‹ ===
if "lang" not in st.session_state:
    st.session_state.lang = "zh"

# === èªè¨€åˆ‡æ› ===
if st.button("ğŸŒ åˆ‡æ›èªè¨€ (Switch Language)"):
    st.session_state.lang = "en" if st.session_state.lang == "zh" else "zh"

TEXT = {
    "zh": {
        "title": "ç´…ç‰†ç†±å½±åƒè™•ç†ç³»çµ±",
        "mode": "é¸æ“‡æ¨è«–æ¨¡å¼",
        "reset": "ğŸ”„ é‡æ•´ä¸¦æ¸…ç©ºçµæœè³‡æ–™å¤¾",
        "reset_done": "å·²æ¸…ç©ºçµæœè³‡æ–™å¤¾ï¼Œè«‹é‡æ–°ä¸Šå‚³åœ–ç‰‡é€²è¡Œåµæ¸¬",
        "upload": "ä¸Šå‚³å…©å¼µåœ–ç‰‡",
        "upload_visible": "ä¸Šå‚³å¯è¦‹å…‰åœ–",
        "upload_thermal": "ä¸Šå‚³ç†±å½±åƒåœ–",
        "wall_and_mask": "ç´…ç‰†åµæ¸¬èˆ‡é»‘è‰²é®ç½©",
        "wall_detect": "ç´…ç‰†åµæ¸¬çµæœ",
        "mask_detect": "é»‘è‰²é®ç½©å¾Œå½±åƒ",
        "leak_detect": "æ»²æ°´åµæ¸¬èˆ‡å¯è¦‹å…‰åŒæ­¥çµæœ",
        "leak_result": "æ»²æ°´åµæ¸¬çµæœ",
        "visible_result": "å¯è¦‹å…‰æ»²æ°´çµæœ",
        "download": "ğŸ“¥ ä¸‹è¼‰æ‰€æœ‰çµæœ",
        "download_done": "çµæœå·²å„²å­˜è‡³ï¼š",
        "no_wall": "æœªåµæ¸¬åˆ°ç´…ç‰†ï¼Œè«‹ç¢ºèªæ¨¡å‹æˆ–è¼¸å…¥å½±åƒ",
        "no_leak": "æœªæ‰¾åˆ°æ»²æ°´åµæ¸¬çµæœï¼Œè«‹æª¢æŸ¥æ¨¡å‹æˆ–è·¯å¾‘è¨­å®š",
        "upload_warn": "è«‹ä¸Šå‚³å…©å¼µåœ–ç‰‡",
        "no_txt": "æ‰¾ä¸åˆ°æ»²æ°´åµæ¸¬æ¨™è¨» .txt æª”æ¡ˆ"
    },
    "en": {
        "title": "Red Brick Wall Thermal Image Processing System",
        "mode": "Select inference mode",
        "reset": "ğŸ”„ Reset and Clear Results Folder",
        "reset_done": "Results folder cleared. Please re-upload images for detection.",
        "upload": "Upload Two Images",
        "upload_visible": "Upload Visible Image",
        "upload_thermal": "Upload Thermal Image",
        "wall_and_mask": "Wall Detection and Black Mask",
        "wall_detect": "Wall Detection Result",
        "mask_detect": "Black Masked Image",
        "leak_detect": "Leak Detection and Visible Image Result",
        "leak_result": "Leak Detection Result",
        "visible_result": "Visible Leak Result",
        "download": "ğŸ“¥ Download All Results",
        "download_done": "Results saved to: ",
        "no_wall": "No wall detected. Please check the model or input image.",
        "no_leak": "No leak detection result found. Please check the model or path settings.",
        "upload_warn": "Please upload two images",
        "no_txt": "Leak detection annotation .txt file not found"
    }
}

# === æ¨™é¡Œ ===
st.title(TEXT[st.session_state.lang]["title"])

# === æ¨¡å¼é¸æ“‡ (YOLO / ONNX) ===
mode = st.radio(TEXT[st.session_state.lang]["mode"], ["YOLO", "ONNX"])

# === æ¸…ç©ºè³‡æ–™å¤¾ ===
def clear_dir(path):
    if os.path.exists(path):
        shutil.rmtree(path)
    os.makedirs(path, exist_ok=True)

if st.button(TEXT[st.session_state.lang]["reset"]):
    clear_dir("runs/predict_filtered")
    clear_dir("runs/predict_masked")
    clear_dir("runs/predict_leakage")
    st.success(TEXT[st.session_state.lang]["reset_done"])
    st.rerun()

# === æ¨¡å‹è¼‰å…¥ ===
def load_model(model_path, url):
    if not os.path.exists(model_path):
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        st.write(f"Downloading model: {model_path} ...")
        with open(model_path, "wb") as f:
            f.write(requests.get(url).content)
        st.success(f"Model downloaded: {model_path}")
    return YOLO(model_path)

def load_onnx_model(model_path, url):
    if not os.path.exists(model_path):
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        st.write(f"Downloading ONNX model: {model_path} ...")
        with open(model_path, "wb") as f:
            f.write(requests.get(url).content)
        st.success(f"ONNX model downloaded: {model_path}")
    return ort.InferenceSession(model_path, providers=["CPUExecutionProvider"])

# === æ ¹æ“šæ¨¡å¼è¼‰å…¥æ¨¡å‹ ===
if mode == "YOLO":
    wall_model = load_model("models/red_wall/best.pt", "https://ä½ çš„æ¨¡å‹ç¶²å€/red_wall_best.pt")
    leak_model = load_model("models/leak/best.pt", "https://ä½ çš„æ¨¡å‹ç¶²å€/leak_best.pt")
else:
    wall_model = load_onnx_model("models/red_wall/best.onnx", "https://ä½ çš„æ¨¡å‹ç¶²å€/red_wall_best.onnx")
    leak_model = load_onnx_model("models/leak/best.onnx", "https://ä½ çš„æ¨¡å‹ç¶²å€/leak_best.onnx")

# === ä¸Šå‚³åœ–ç‰‡ ===
st.markdown(f"### {TEXT[st.session_state.lang]['upload']}")
col_upload1, col_upload2 = st.columns(2)
with col_upload1:
    visible_img = st.file_uploader(TEXT[st.session_state.lang]["upload_visible"], type=["jpg", "png", "jpeg"])
with col_upload2:
    thermal_img = st.file_uploader(TEXT[st.session_state.lang]["upload_thermal"], type=["jpg", "png", "jpeg"])

# === Canny é‚Šç·£æª¢æ¸¬ ===
def apply_canny(img_array):
    gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    return cv2.Canny(blurred, 50, 150)

# === ONNX æ¨è«– ===
def run_onnx_inference(session, img_path):
    img = cv2.imread(img_path)
    img_resized = cv2.resize(img, (640, 640))
    img_input = img_resized.transpose(2, 0, 1) / 255.0
    img_input = np.expand_dims(img_input, axis=0).astype(np.float32)
    input_name = session.get_inputs()[0].name
    outputs = session.run(None, {input_name: img_input})
    return outputs

# === ä¸»æµç¨‹ ===
if visible_img and thermal_img:
    col_show1, col_show2 = st.columns(2)
    with col_show1:
        st.image(visible_img, caption=TEXT[st.session_state.lang]["upload_visible"], use_container_width=True)
    with col_show2:
        st.image(thermal_img, caption=TEXT[st.session_state.lang]["upload_thermal"], use_container_width=True)

    thermal_np = np.array(Image.open(thermal_img).convert("RGB"))[..., ::-1]
    edges = apply_canny(thermal_np)
    canny_path = "canny_result.jpg"
    cv2.imwrite(canny_path, edges)

    if mode == "YOLO":
        wall_results = wall_model.predict(canny_path, save=True, project="runs", name="predict_filtered", exist_ok=True)
    else:
        wall_results = run_onnx_inference(wall_model, canny_path)
        st.write("ONNX ç´…ç‰†æ¨è«–çµæœ:", wall_results)

else:
    st.warning(TEXT[st.session_state.lang]["upload_warn"])
